{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams = plt.rcParamsOrig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is adapted from [Probabilistic Programming and Bayesian Methods for Hackers](https://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter4_TheGreatestTheoremNeverTold/Ch4_LawOfLargeNumbers_PyMC3.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_conversion_rate(converted, bounced, samples=20000):\n",
    "    N = converted + bounced\n",
    "    with pm.Model() as model:\n",
    "        conversion_rate = pm.Uniform(\"conversion_rate\", 0, 1)\n",
    "        observations = pm.Binomial(\"obs\", N, conversion_rate, observed=converted)\n",
    "        \n",
    "        trace = pm.sample(samples, tune=2000, step=pm.Metropolis())\n",
    "    \n",
    "    burned_trace = trace[int(samples/4):]\n",
    "    return burned_trace[\"conversion_rate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take some samples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = posterior_conversion_rate(313, 1027 - 313)\n",
    "b = posterior_conversion_rate(308, 1032 - 308)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "sns.histplot(x=a, element='step', fill=False, label='A', ax=ax)\n",
    "sns.histplot(x=b, element='step', fill=False, label='B', ax=ax)\n",
    "plt.xlabel('conversion rate')\n",
    "plt.ylabel('freq')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do it ourselves so we can actually modify the results as we want. In this case, we reframe the problem from $p(a > b)$ to $p(a-b > 0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_a = 313\n",
    "converted_b = 308\n",
    "N_a = 1027\n",
    "N_b = 1032\n",
    "bounced_a = N_a - converted_a\n",
    "bounced_b = N_b - converted_b\n",
    "\n",
    "with pm.Model() as model:\n",
    "    p_a = pm.Uniform(\"p_a\", 0, 1)\n",
    "    p_b = pm.Uniform(\"p_b\", 0, 1)\n",
    "    y_a = pm.Binomial(\"y_a\", N_a, p_a, observed=converted_a)\n",
    "    y_b = pm.Binomial(\"y_b\", N_b, p_b, observed=converted_b)\n",
    "    diff = pm.Deterministic('p_a-p_b', p_a - p_b)\n",
    "\n",
    "    trace = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "with model:\n",
    "    display(az.summary(trace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows that the mean of $CTP_B$ is larger thatn $CTP_A$, but is it always the case that $CTP_B > CTP_A$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    az.plot_posterior(trace, var_names=['p_a', 'p_b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out, we can just subtract both CTPs! The interpretation of the following figure should be quite intuitive: the probability of seeing option A gets more conversion than option B is only 0.0568 which means it is more likely to see the opposite!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    az.plot_posterior(\n",
    "        trace,\n",
    "        var_names=['p_a-p_b'],\n",
    "        ref_val=0\n",
    "    )\n",
    "    plt.title('$P(a-b > 0) = {:.4f}$'.format(\n",
    "        (trace['p_a-p_b'] > 0).mean()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Search Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will generate a random dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "no_prop = 10\n",
    "all_ratings = pd.DataFrame()\n",
    "\n",
    "for i in range(no_prop):\n",
    "    no_ratings = max(0, int(40*np.random.standard_t(3)+50))\n",
    "    ratings = pd.DataFrame({\n",
    "        'property_id': [i] * no_ratings,\n",
    "        'rating': np.round(10*np.random.beta(7, 2, size=no_ratings), 0)\n",
    "    })\n",
    "    all_ratings = pd.concat([\n",
    "        all_ratings,\n",
    "        ratings\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's report the summary statistics. Also, order the properties based on their average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_review = all_ratings.groupby('property_id').agg({\n",
    "    'rating': ['mean', 'std', 'sum', 'count']\n",
    "}).rating.reset_index()\n",
    "\n",
    "(\n",
    "    agg_review[['property_id','mean','std','count']]\n",
    "    .sort_values('mean', ascending=False)\n",
    "    .set_index('property_id')\n",
    "    .style\n",
    "    .format({\n",
    "        'mean': '{:.2f}',\n",
    "        'std': '{:.2f}'\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can dig deeper in this problem. Let's take two example properties: prop 3 and 6. Our \"usual\" solution will look like the following figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def draw_norm(property_id, ax):\n",
    "    prop = all_ratings.query('property_id == {}'.format(property_id))\n",
    "    no_ratings = len(prop)\n",
    "\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    ax.plot(\n",
    "        x*10,\n",
    "        norm.pdf(x*10, prop.rating.mean(), prop.rating.std()),\n",
    "        label='Prop {} (N={})'.format(property_id, len(prop))\n",
    "    )\n",
    "\n",
    "ax = plt.gca()\n",
    "draw_norm(3, ax)\n",
    "draw_norm(6, ax)\n",
    "plt.xlim([0,10])\n",
    "plt.xlabel('review score')\n",
    "plt.ylabel('density')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in the previous figure that we don't really take N into account. We should be more certain when we see larger number of samples. What can we do to incorporate this? Use beta distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "def draw_beta(property_id, ax):\n",
    "    prop = all_ratings.query('property_id == {}'.format(property_id))\n",
    "    no_ratings = len(prop)\n",
    "\n",
    "    x = np.linspace(0, 1, 500)\n",
    "    ax.plot(\n",
    "        x,\n",
    "        beta.pdf(x, 1+prop.rating.sum()/10, 1+no_ratings-prop.rating.sum()/10),\n",
    "        label='Prop {} (N={})'.format(property_id, len(prop))\n",
    "    )\n",
    "    \n",
    "ax = plt.gca()\n",
    "draw_beta(3, ax)\n",
    "draw_beta(6, ax)\n",
    "plt.xlabel('review score')\n",
    "plt.ylabel('density')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prop 6 which has more ratings is more certain about the true review score! Yay! However, as we are recommending our properties to our customers, and we consider ourselves customer-centric, we should be more cautious, no?\n",
    "\n",
    "Therefore, we can use the *95% least plausible value*.\n",
    "\n",
    "> Why is sorting based on this quantity a good idea? By ordering by the 95% least plausible value, we are being the most conservative with what we think is best. [(Davidson-Pilon, 2015)](https://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter4_TheGreatestTheoremNeverTold/Ch4_LawOfLargeNumbers_PyMC3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Code\n",
    "\n",
    "We can use a similar codebase to the one we've written before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_score(N, sum_of_ratings, samples=20000):\n",
    "    gap_from_perfect_ratings = N - sum_of_ratings\n",
    "    with pm.Model() as model:\n",
    "        true_score = pm.Uniform(\"true_score\", 0, 1)\n",
    "        observations = pm.Binomial(\"obs\", N, true_score, observed=sum_of_ratings)\n",
    "        \n",
    "        trace = pm.sample(samples, tune=1500)\n",
    "    \n",
    "    burned_trace = trace[int(samples/4):]\n",
    "    return burned_trace[\"true_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "for i, row in agg_review.filter(regex='(1|2|9)', axis=0).iterrows():\n",
    "    true_score = posterior_score(row['count'], row['sum']/10, 5000)\n",
    "    sns.histplot(\n",
    "        true_score,\n",
    "        label=f\"Prop {row['property_id']:.0f} (N={row['count']:.0f})\",\n",
    "        stat='density',\n",
    "        element='step',\n",
    "        fill=False,\n",
    "        ax=ax\n",
    "    )\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production-friendly Code\n",
    "\n",
    "The following code is from the analytical solution, i.e. deriving the posterior distribution and using the normal/Gaussian distribution approximation to the beta distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "X &\\sim Beta(a, b) \\\\\n",
    "E[X] &= \\frac{a}{a + b} \\\\\n",
    "SD[X] &= \\sqrt{\\frac{ab}{(a+b)^2(a + b + 1)}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_bound(a, b):\n",
    "    mean = a / (a + b)\n",
    "    stdev = 1.65 * np.sqrt((a*b)/((a+b)**2 * (a + b + 1)))\n",
    "    return mean, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_review['mle'] = agg_review['mean']\n",
    "posterior_mean, std_err = lower_bound(\n",
    "    1 + agg_review['sum'] / 10,\n",
    "    1 + agg_review['count'] - agg_review['sum'] / 10\n",
    ")\n",
    "agg_review['lower'] = pd.Series(posterior_mean) - pd.Series(std_err)\n",
    "agg_review['posterior_mean'] = posterior_mean\n",
    "agg_review['std_err'] = std_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_review['a'] = agg_review['sum'] / 10\n",
    "agg_review['b'] = agg_review['count'] - agg_review['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "for pid in [1, 2, 9]:\n",
    "    plt.step(x*10, beta.pdf(x, agg_review['a'][pid], agg_review['b'][pid]), where='mid')\n",
    "plt.xlabel('review score')\n",
    "plt.ylabel('density')\n",
    "plt.savefig('review-hist.png', bbox_inches='tight', transparent=True, dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.argsort(agg_review['lower']).values\n",
    "ax = plt.gca()\n",
    "ax.errorbar(\n",
    "    x=agg_review.iloc[order]['posterior_mean']*10,\n",
    "    y=np.arange(len(order)),\n",
    "    xerr=agg_review.iloc[order]['std_err']*10,\n",
    "    capsize=0,\n",
    "    fmt='o'\n",
    ")\n",
    "plt.xlim(0, 10)\n",
    "plt.yticks(range(len(agg_review)), agg_review.iloc[order]['property_id'])\n",
    "plt.xlabel('review score')\n",
    "plt.ylabel('property id')\n",
    "plt.savefig('ranking.png', bbox_inches='tight', transparent=True, dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "> As I mentioned in my recent post, my paper has been accepted for poster presentation at Bayesian Optimisation Workshop at NIPS 2016. List of accepted paper has also appeared on the workshop’s website. There are 26 papers accepted in total. From the submission, my paper was given ID 12 and appears 9th on the list.\n",
    "> Since the list of accepted papers is not ordered in alphabetical order (title nor author), I assume the list is ordered by the submission ID. I also assume that the submission ID is given by the order of submission. The question is “given the above information, estimate how many papers were submitted to BayesOpt 2016?”\n",
    "\n",
    "*Hint: Binomial distribution is your friend.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "With the `mpg` dataset, what is the effect of adding more weights to fuel consumption?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset('mpg')\n",
    "sns.lmplot(\n",
    "    x='weight',\n",
    "    y='mpg',\n",
    "    data=df\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
